---
tags:
  - Papers
---
https://arxiv.org/pdf/2301.05217
Neel Nanda and UC Berkeley, early 2023 (1 year after the grokking paper came out)
Also I think illustrated in the niche-popular [transformerlens notebook](https://transformerlens-intro.streamlit.app/TransformerLens_&_induction_circuits), also by Neel Nanda and co.

- They helpfully did the robustness study to show that this reproduces in many similar experiments
- `In Section 5.3 we find that grokking does not occur without regularization.` in some contradiction to how I understand [[Grokking- Generalization Beyond Overfitting on Small Algorithmic Datasets||the original grokking paper]].
- "progress measures" is [[Hidden Progress in Deep Learning- SGD Learns Parities Near the Computational Limit||this paper]].
- Other refs:
	- [[Towards Understanding Grokking- An Effective Theory of Representation Learning]]
	- [[The Slingshot Mechanism- An Empirical Study of Adaptive Optimizers and the Grokking Phenomenon]]
	- 